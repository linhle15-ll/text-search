{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d5cd72",
   "metadata": {},
   "source": [
    "## Task 1: Search by name and address separately\n",
    "Given structured data of hospitals as Objects and their metadata, search the name or the address and give the results\n",
    "\n",
    "### Approach:\n",
    "Since the data is well structured with clear fields, we can approach the problem with keyword search.\n",
    "For this problem, I use BM25 Algorithm with a bit of twist to adapt to the given database given that it is a suitable algorithm for keyword search, especially in Vietnamese in this problem. \n",
    "\n",
    "For experiment purpose, I migh try two methods: one with keyword search, and one with semantic search (for semantic search, the context is pretty limited actually since the data given are in separate objects and with no context)\n",
    "\n",
    "### Reference resources:\n",
    "- BM25: \n",
    "- Read more about BM25 on Elastic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba81e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyvi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# pyvi tách từ tiếng Việt\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyvi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mViTokenizer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tokenize \n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstring\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyvi'"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "import json\n",
    "\n",
    "# pyvi tách từ tiếng Việt\n",
    "from pyvi.ViTokenizer import tokenize \n",
    "import re, os, string\n",
    "import pandas as pd\n",
    "import math \n",
    "import numpy as np\n",
    "\n",
    "fileName = \"data/20250612.json\"\n",
    "\n",
    "try:\n",
    "    with open(fileName, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {fileName} not found.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: Invalid JSON format in {fileName}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2e975c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cleaning, normalization, and segmentation function \n",
    "# Xóa bỏ các kí tự thừa trong text\n",
    "def cleanText(text):\n",
    "    text = re.sub('<.*?>', '', text).strip()\n",
    "    text = re.sub('(\\s)+', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Chuẩn hóa văn bản, xóa bỏ các kí tự _ và chuyển sang chữ thường\n",
    "def normalizeText(text):\n",
    "    listPunctuation = string.punctuation.replace('_', '')\n",
    "    for i in listPunctuation:\n",
    "        text = text.replace(i, '')\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "# Thực hiện tách từ (tiếng Việt)\n",
    "def tokenizeText(sent):\n",
    "    sent = tokenize(sent.encode('utf-8').decode('utf-8'))\n",
    "    return sent.split()\n",
    "\n",
    "# combine label and dia_chi\n",
    "def preprocessData(data):\n",
    "    docs = []\n",
    "    \n",
    "    for doc in data:\n",
    "        label = doc.get('label') or ''\n",
    "        diachi = doc.get('diachi') or ''\n",
    "        text = label + ' ' + diachi\n",
    "        \n",
    "        # clean, normalize and tokenize texts\n",
    "        cleanedText = cleanText(text)\n",
    "        normalizedText = normalizeText(cleanedText)\n",
    "        tokenizedText = tokenizeText(normalizedText)\n",
    "        \n",
    "        docs.append(tokenizedText)\n",
    "        \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e2052",
   "metadata": {},
   "source": [
    "### Some notes\n",
    "- Higher (Caps Locks) texts (E,g., DS and ds, Phòng khám and phòng khám)\n",
    "- Abbreviations (E.g., BV and Bệnh Viện, Phòng khám đa khoa and PVDK/ PKĐK, Dược sĩ and DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0031d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng mô hình BM25:\n",
    "class BM25:\n",
    "    def __init__(self, k1=1.5, b=0.75):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        \n",
    "    def fit(self, corpus):\n",
    "        '''\n",
    "        fit the statistics that are requird to calculate Bm25 ranking score using the corpus given\n",
    "        \n",
    "        Params:\n",
    "        ---------\n",
    "        corpus: list[list[str]]\n",
    "        Each element in the list represents a document, and each document is a list of the terms\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        self\n",
    "        '''\n",
    "        tf = [] # list[dict[str, int]]: term frequency in each document by order (document 1 --> document n)\n",
    "        df = {} # dict[str, int]: document frequency number of docs in the text file that contains the term\n",
    "        idf = {} # IDF of the term\n",
    "        docLen = [] # list[int]: num of terms in each document\n",
    "        corpusSize = len(corpus) # int: num of documents in the text file\n",
    "        \n",
    "        for document in corpus:\n",
    "            docLen.append(len(document))\n",
    "            \n",
    "            # Compute tf - term frequency per document\n",
    "            frequencies = {}\n",
    "            for term in document:\n",
    "                termCount = frequencies.get(term, 0) + 1\n",
    "                frequencies[term] = termCount\n",
    "                \n",
    "            tf.append(frequencies)\n",
    "            \n",
    "            # compute df - document frequency per term\n",
    "            for term, _ in frequencies.items(): # term and their tf in each document \n",
    "                dfCount = df.get(term, 0) + 1\n",
    "                df[term] = dfCount\n",
    "                \n",
    "        # calculate the idf of the terms\n",
    "        for term, freq in df.items():\n",
    "            idf[term] = math.log(1 + (corpusSize - freq + 0.5) / (freq + 0.5))\n",
    "            \n",
    "        self.tf_ = tf\n",
    "        self.df_ = df\n",
    "        self.idf_ = idf\n",
    "        self.docLen_ = docLen\n",
    "        self.corpus_ = corpus\n",
    "        self.corpusSize_ = corpusSize\n",
    "        self.avgDocLen_ = sum(docLen) / corpusSize # float: the average number of terms in each document in the text file\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    # score of the query in each document\n",
    "    def scoreCalc(self, query, index):\n",
    "        score = float(0)\n",
    "        docLen = self.docLen_[index]\n",
    "        frequencies = self.tf_[index]\n",
    "        \n",
    "        for term in query:\n",
    "            if term not in frequencies:\n",
    "                continue\n",
    "            \n",
    "            # Check if term exists in idf (avoid KeyError)\n",
    "            if term not in self.idf_:\n",
    "                continue\n",
    "                \n",
    "            freq = frequencies[term]\n",
    "            numerator = self.idf_[term] * freq * (self.k1 + 1)\n",
    "            denominator = freq + self.k1 * (1 - self.b + self.b * docLen / self.avgDocLen_)\n",
    "            \n",
    "            # sum\n",
    "            score += (numerator / denominator)\n",
    "        \n",
    "        return score \n",
    "    \n",
    "    def search(self, query):\n",
    "        scores = [self.scoreCalc(query, index) for index in range(self.corpusSize_)]\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a065d8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.BM25 at 0x2e2d41425e0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process and get texts\n",
    "docs = preprocessData(data)\n",
    "\n",
    "# Train model - pass the processed documents (docs already contains tokenized text)\n",
    "bm25 = BM25()\n",
    "bm25.fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83638c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original query: 'Nha khoa Viet Smile'\n",
      "Processed tokens: ['nha_khoa', 'viet', 'smile']\n",
      "Scores for all documents: [2.4935080701543106, 0.0, 2.360567086561884, 3.0004387285340606, 0.0, 0.0, 2.902105625529104, 3.2185492864155862, 2.6423164428879966, 0.0, 0.0, 0.0, 3.2185492864155862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7235859602387795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7235859602387795, 2.6423164428879966, 2.8100133170532375, 2.902105625529104, 3.1056692521171163, 2.8100133170532375, 0.0, 0.0, 3.2185492864155862, 0.0, 0.0, 0.0, 2.902105625529104, 0.0, 2.4252171177607713, 2.8100133170532375, 3.0004387285340606, 0.0, 0.0, 0.0, 0.0, 2.6423164428879966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6423164428879966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.082938283682268, 0.0, 3.1056692521171163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7235859602387795, 2.4252171177607713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6423164428879966, 0.0, 0.0, 2.6423164428879966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8100133170532375, 0.0, 3.1056692521171163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.902105625529104, 0.0, 0.0, 3.0004387285340606, 0.0, 2.241084049235965, 0.0, 0.0, 0.0, 0.0, 2.6423164428879966, 2.360567086561884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.339944388910212, 0.0, 0.0, 2.5657564262606556, 0.0, 0.0, 2.8100133170532375, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0004387285340606, 0.0, 0.0, 2.6423164428879966, 0.0, 0.0, 2.902105625529104, 2.6423164428879966, 0.0, 0.0, 0.0, 2.7235859602387795, 0.0, 0.0, 0.0, 2.7235859602387795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6423164428879966, 0.0, 0.0, 0.0, 0.0, 2.902105625529104, 0.0, 0.0, 2.5657564262606556, 2.902105625529104, 3.2185492864155862, 0.0, 2.7235859602387795, 0.0, 0.0, 3.1056692521171163, 2.299274364234487, 0.0, 0.0, 0.0, 2.7235859602387795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8100133170532375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6423164428879966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1056692521171163, 2.902105625529104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7235859602387795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.902105625529104, 0.0, 3.0004387285340606, 0.0, 0.0, 0.0, 0.0, 2.4252171177607713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7235859602387795, 0.0, 0.0, 0.0, 0.0, 3.0004387285340606, 3.2185492864155862, 3.0004387285340606, 0.0, 2.902105625529104, 0.0, 0.0, 2.902105625529104, 2.8100133170532375, 0.0, 0.0, 2.902105625529104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8100133170532375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0004387285340606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7235859602387795, 3.339944388910212, 3.2185492864155862, 2.902105625529104, 3.0004387285340606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.902105625529104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0004387285340606, 0.0, 0.0, 2.8100133170532375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8100133170532375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5657564262606556, 9.69562442673868, 2.8100133170532375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2185492864155862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6423164428879966, 0.0, 0.0, 2.6423164428879966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.902105625529104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6423164428879966, 2.5657564262606556, 0.0, 0.0, 2.6423164428879966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.249077981943461, 2.5657564262606556, 0.0, 2.5657564262606556, 0.0, 0.0, 0.0, 0.0, 2.7235859602387795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.339944388910212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7235859602387795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.902105625529104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4252171177607713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.2185492864155862, 0.0, 2.4252171177607713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7235859602387795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4935080701543106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.902105625529104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.5713131110393554, 2.8100133170532375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.5713131110393554, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5657564262606556, 0.0, 3.1056692521171163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6423164428879966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4252171177607713, 0.0, 0.0, 0.0, 0.0, 3.1056692521171163, 0.0, 0.0, 0.0, 0.0, 3.4708558215805763, 0.0, 0.0, 2.4252171177607713, 0.0, 0.0, 2.902105625529104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4252171177607713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5657564262606556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.902105625529104, 3.2185492864155862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4252171177607713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.902105625529104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.902105625529104, 3.0004387285340606, 3.1056692521171163, 0.0, 10.048025899332476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8100133170532375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.339944388910212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7235859602387795, 3.1056692521171163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1056692521171163, 0.0, 3.2185492864155862, 2.8100133170532375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6423164428879966, 0.0, 2.4935080701543106, 2.4935080701543106, 2.5657564262606556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6423164428879966, 0.0, 0.0, 2.7235859602387795, 2.7235859602387795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0004387285340606, 2.7235859602387795, 3.339944388910212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1056692521171163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4935080701543106, 2.5657564262606556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4252171177607713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.241084049235965, 2.5657564262606556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.902105625529104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0949134089294175, 2.4252171177607713, 2.902105625529104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.4935080701543106, 0.0, 2.4935080701543106, 0.0, 0.0, 0.0, 2.4935080701543106, 0.0, 0.0, 2.4252171177607713, 0.0, 0.0, 0.0, 0.0, 2.7235859602387795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7235859602387795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8100133170532375, 0.0, 0.0, 2.5657564262606556, 0.0, 0.0, 0.0, 0.0, 2.5657564262606556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6423164428879966, 0.0, 0.0, 0.0, 7.5713131110393554, 2.7235859602387795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.9456409445764196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6423164428879966, 0.0, 0.0, 0.0, 3.1056692521171163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.360567086561884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.22269112188174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6423164428879966, 0.0, 2.5657564262606556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5657564262606556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.902105625529104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.902105625529104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0004387285340606, 0.0, 0.0, 3.1056692521171163, 2.6423164428879966, 0.0, 0.0, 0.0, 2.082938283682268, 2.7235859602387795, 2.8100133170532375, 0.0, 2.8100133170532375, 2.902105625529104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.902105625529104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.902105625529104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.902105625529104, 0.0, 0.0, 0.0, 0.0, 0.0, 2.360567086561884, 2.4252171177607713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.360567086561884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.772612775075682, 3.1056692521171163, 2.902105625529104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8100133170532375, 0.0, 0.0, 0.0, 2.6423164428879966, 0.0, 0.0, 0.0, 0.0, 2.4935080701543106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Top 10 most relevant results: \n",
      "\n",
      "Rank 1: Score = 18.2227\n",
      "Name: Nha khoa Viet Smile - Thanh Xuân\n",
      "Address: 229 Giáp Nhất, Nhân Chính, Thanh Xuân, Hà nội \n",
      "Rank 2: Score = 10.0480\n",
      "Name: Nha khoa Saigon Smile\n",
      "Address: 70 Hoàng Diệu, P.12, Q.4, TP. HCM\n",
      "Rank 3: Score = 9.6956\n",
      "Name: Nha khoa Sài Gòn Smile\n",
      "Address: 70 Hoàng Diệu, phường 12, quận 4, Tp.HCM \n",
      "Rank 4: Score = 8.7726\n",
      "Name: Nha khoa Happy Smile Land\n",
      "Address: 25A1 Trần Duy Hưng, P. Trung Hòa, Q. Cầu Giấy, Hà Nội\n",
      "Rank 5: Score = 8.2491\n",
      "Name: Nha Khoa Smile Care\n",
      "Address: Nhà C101, ngõ Thái Hà, phường Láng Hạ, quận Đống Đa, Tp. Hà Nội.\n",
      "Rank 6: Score = 7.5713\n",
      "Name: Nha khoa Tâm Đức Smile (CS Tân Kỳ)\n",
      "Address: Số 52 Tân Kỳ Tân Quý, P. Tây Hạnh, Q. Tân Phú, TP. HCM\n",
      "Rank 7: Score = 7.5713\n",
      "Name: Nha khoa True Smile - Đặng Văn Ngữ\n",
      "Address: 161 Đặng Văn Ngữ, phường Phương Liên - Trung Tự, quận Đống Đa, Hà Nội\n",
      "Rank 8: Score = 7.5713\n",
      "Name: Nha khoa Tâm Đức Smile Cần Thơ\n",
      "Address: 135G đường Trần Hưng Đạo, P. Thới Bình, Quận Ninh Kiều, TP Cần Thơ\n",
      "Rank 9: Score = 4.0949\n",
      "Name: Nha khoa Happy (Nha Khoa Vũ Duy Hưng)\n",
      "Address: 26 Hàm Nghi, Thạc Gián, Thanh Khê, Đà Nẵng\n",
      "Rank 10: Score = 3.4709\n",
      "Name: Nha khoa ACA\n",
      "Address: 453-455 Hoàng diệu, Hải châu, Đà nẵng\n"
     ]
    }
   ],
   "source": [
    "limit = 10\n",
    "query = \"Nha khoa Viet Smile\"\n",
    "\n",
    "# Process query the same way as individual documents (not using preprocessData)\n",
    "cleanedQuery = cleanText(query)\n",
    "normalizedQuery = normalizeText(cleanedQuery)\n",
    "queryTokens = tokenizeText(normalizedQuery)\n",
    "\n",
    "print(f\"Original query: '{query}'\")\n",
    "print(f\"Processed tokens: {queryTokens}\")\n",
    "\n",
    "# Get BM25 scores for each document\n",
    "scores = bm25.search(queryTokens)\n",
    "\n",
    "print(f\"Scores for all documents: {scores}\")\n",
    "\n",
    "# Sort documents by relevance to the query\n",
    "results = [(i, score) for i, score in enumerate(scores)]\n",
    "results.sort(key=lambda x: x[1], reverse=True) #x[1]: score\n",
    "\n",
    "# Top k results\n",
    "print(f\"Top {limit} most relevant results: \\n\")\n",
    "\n",
    "for rank, (docIndex, score) in enumerate(results[:limit], 1):\n",
    "    if score > 0:\n",
    "        docData = data[docIndex]\n",
    "        label = docData.get('label', 'N/A')\n",
    "        diachi = docData.get('diachi', 'N/A')\n",
    "        \n",
    "        print(f\"Rank {rank}: Score = {score:.4f}\")\n",
    "        print(f\"label: {label}\")\n",
    "        print(f\"diachi: {diachi}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
